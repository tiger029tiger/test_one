{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# 第7讲-网络爬虫常见技巧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 模拟登录\n",
    "2. 常见验证码突破\n",
    "3. 爬虫代理池\n",
    "4. SSL认证问题\n",
    "5. 设计健壮的爬虫\n",
    "6. 各种爬虫的坑\n",
    "7. 爬虫攻防小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 模拟登录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1常规模拟登录\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "try:\n",
    "    # python 2\n",
    "    import cookielib\n",
    "except:\n",
    "    # python 3\n",
    "    import http.cookiejar as cookielib\n",
    "        \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import http.cookiejar as cookielib\n",
    "from bs4 import BeautifulSoup\n",
    "filename = 'cookieOfCsdn.txt'\n",
    "cookie = cookielib.MozillaCookieJar(filename)\n",
    "handler = urllib.request.HTTPCookieProcessor(cookie)\n",
    "opener = urllib.request.build_opener(handler)\n",
    "loginurl = 'https://passport.csdn.net/account/login?from=http%3A%2F%2Fmy.csdn.net%2Fmy%2Fmycsdn'\n",
    "response = opener.open(loginurl)\n",
    "soup = BeautifulSoup(response.read(), 'html.parser')\n",
    "for input in soup.form.find_all('input'):\n",
    "    if input.get(\"name\") == \"lt\":\n",
    "        lt = input.get(\"value\")\n",
    "    if input.get(\"name\") == \"execution\":\n",
    "        execution = input.get(\"value\")\n",
    "values = {\n",
    "     'username':'username',\n",
    "     'password':'passwd',\n",
    "     'lt':lt,\n",
    "     'execution':execution,\n",
    "     '_eventId':'submit'\n",
    " }\n",
    "postdata = urllib.parse.urlencode(values).encode(encoding='UTF8')\n",
    "print(postdata)\n",
    "opener.addheaders = [(\"User-Agent\", \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36\")]\n",
    "\n",
    "result = opener.open(loginurl, postdata)\n",
    "cookie.save(ignore_expires=True, ignore_discard=True)\n",
    "url1 = \"http://my.csdn.net/my/mycsdn\"\n",
    "result1 = opener.open(url1)\n",
    "print(result1.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2利用selenium做模拟登录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "案例：微信公众号信息抓取\n",
    "\n",
    "https://wx.qq.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 通过Selenium调用Chrome登录web版微信\n",
    "2. 模拟登录\n",
    "3. 点击切换到公众号面板\n",
    "4. 爬取公众号数据\n",
    "5. 定时刷新页面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser.get('https://wx.qq.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. 模拟登录\n",
    "#3. 点击切换到公众号面板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(browser.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. 定时刷新页面技巧\n",
    "\n",
    "import time  \n",
    "from selenium import webdriver  \n",
    "  \n",
    "browser = webdriver.Chrome()  \n",
    "browser.maximize_window()  \n",
    "browser.implicitly_wait(6)  \n",
    "  \n",
    "browser.get(\"https://www.baidu.com\")  \n",
    "time.sleep(3)  \n",
    "try:  \n",
    "    browser.refresh()\n",
    "    print('刷新成功')  \n",
    "except Exception as e:  \n",
    "    print(\"Error\", format(e))\n",
    "    \n",
    "browser.quit()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 常见验证码突破"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. pytesseract图像识别\n",
    "# 2. 基于机器学习的图像识别\n",
    "# 3. 基于深度学习的图像识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 爬虫代理池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. User-Agent 更换\n",
    "# 2. ip更换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. User-Agent 更换\n",
    "\n",
    "#http://hexingxing.cn/ua-user-agent-browser/\n",
    "#user agent大全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import random\n",
    "\n",
    "user_agent_list = [\n",
    "            \"Mozilla/5.0\",\n",
    "            \"Mozilla/5.1\"\n",
    "]\n",
    "\n",
    "user_agent = random.choice(user_agent_list) \n",
    "headers = {'User-Agent': user_agent}\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. ip更换\n",
    "# ip池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://www.xicidaili.com/nn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_url(url):     # 获取免费代理ip\n",
    "    url_list = []\n",
    "    for i in range(1,100):\n",
    "        url_new = url + str(i)\n",
    "        url_list.append(url_new)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_content(url):     # 免费代理ip的每个页面\n",
    "    \n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'}\n",
    "    req = urllib.request.Request(url=url, headers=headers)\n",
    "    res = urllib.request.urlopen(req)\n",
    "    content = res.read()\n",
    "    return content.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_info(content):      # 获取代理ip内容\n",
    "    ip = etree.HTML(content).xpath('//table[contains(@id,\"ip_list\")]/tr/td[2]/text()')\n",
    "    port = etree.HTML(content).xpath('//table[contains(@id,\"ip_list\")]/tr/td[3]/text()')\n",
    "    with open(\"data.txt\", \"w\") as f:\n",
    "        for i in range(0,len(ip)):\n",
    "            out = \"\"\n",
    "            out += \"\" + ip[i]\n",
    "            out += \":\" + port[i]\n",
    "            f.write(out + \"\\n\")     # 写入data.txt文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def verify_ip(ip,port):    # 验证爬下来的ip有效性\n",
    "    \n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'}\n",
    "    \n",
    "    proxy = {'http':'http://%s:%s'%(ip,port)}\n",
    "    print(proxy)\n",
    "\n",
    "    proxy_handler = urllib.request.ProxyHandler(proxy)\n",
    "    opener = urllib.request.build_opener(proxy_handler)\n",
    "    urllib.request.install_opener(opener)\n",
    "\n",
    "    test_url = \"https://www.baidu.com/\"\n",
    "    req = urllib.request.Request(url=test_url,headers=headers)\n",
    "    time.sleep(6)\n",
    "    try:\n",
    "        res = urllib.request.urlopen(req)\n",
    "        time.sleep(3)\n",
    "        content = res.read()\n",
    "        if content:\n",
    "            print('ip可用')\n",
    "            with open(\"data_verify.txt\", \"a\") as f:\n",
    "                f.write(ip + \":\" + port)\n",
    "                f.write(\"\\n\")\n",
    "        else:\n",
    "            print('ip不可用')\n",
    "    except urllib.request.URLError as e:\n",
    "        print(e.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import time\n",
    "from lxml import etree\n",
    "\n",
    "url = 'http://www.xicidaili.com/nn/'\n",
    "url_list = get_url(url)\n",
    "for i in url_list:\n",
    "    print(i)\n",
    "    content = get_content(i)\n",
    "    time.sleep(3)\n",
    "    get_info(content)\n",
    "    \n",
    "with open(\"data.txt\", \"r\") as f:\n",
    "    data_list = f.readlines()\n",
    "    for data in data_list:\n",
    "        print(data.split(\":\")[0])\n",
    "        verify_ip(data.split(\":\")[0],data.split(\":\")[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SSL认证问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wandergis.com/hospital-viz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = requests.get('https://wandergis.com/hospital-viz/', headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSL证书是数字证书的一种，类似于驾驶证、护照和营业执照的电子副本。因为配置在服务器上，也称为SSL服务器证书。SSL 证书就是遵守 SSL协议，由受信任的数字证书颁发机构CA，在验证服务器身份后颁发，具有服务器身份验证和数据传输加密功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> SSL Cert Verification Requests verifies SSL certificates for HTTPS requests, just like a web browser. By default, SSL verification is enabled, and Requests will throw a SSLError if it's unable to verify the certificate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://docs.python-requests.org/en/latest/user/advanced/#ssl-cert-verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get的verify=False参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a.status_code\n",
    "#a.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 设计健壮的爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5.1 关于异常"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 由于爬虫常常遇到网站的各种情况，比如中断，页面更改等，我们在下载页面时，会做很多异常处理的动作，尽量保证下载不受到各种中断的影响。\n",
    "    \n",
    "- 下面按照简单到复杂，易干扰到健壮的方式，介绍关于异常的处理："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 1.简单下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "# 便于创建绝对路径\n",
    "import urlparse\n",
    "\n",
    "\n",
    "def download1(url):\n",
    "    \"\"\"简单直接下载\"\"\"\n",
    "    return urllib2.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 2.捕获异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import urlparse\n",
    "\n",
    "def download2(url):\n",
    "    \"\"\"可以捕获一般的网络异常 \"\"\"\n",
    "    print 'Downloading:', url\n",
    "    try:\n",
    "        html = urllib2.urlopen(url).read()\n",
    "    except urllib2.URLError as e:\n",
    "        print 'Download error:', e.reason\n",
    "        html = None\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 3.下载重试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import urlparse\n",
    "\n",
    "def download3(url, num_retries=5):\n",
    "    \"\"\"如果捕获5XX（服务器状态）相关异常，可以进行重试操作\"\"\"\n",
    "    print 'Downloading:', url\n",
    "    try:\n",
    "        html = urllib2.urlopen(url).read()\n",
    "    except urllib2.URLError as e:\n",
    "        print 'Download error:', e.reason\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # 进行重试连接\n",
    "                html = download3(url, num_retries-1)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "httpstat.us/500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4.添加UA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import urlparse\n",
    "\n",
    "\n",
    "def download4(url, user_agent='ua', num_retries=5):\n",
    "    \"\"\"添加user agent 连接\"\"\"\n",
    "    print 'Downloading:', url\n",
    "    headers = {'User-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'}\n",
    "    request = urllib2.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib2.urlopen(request).read()\n",
    "    except urllib2.URLError as e:\n",
    "        print 'Download error:', e.reason\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # 进行重试连接\n",
    "                html = download4(url, user_agent, num_retries-1)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5.添加代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import urlparse\n",
    "\n",
    "def download5(url, user_agent='ua', proxy=None, num_retries=5):\n",
    "    \"\"\"支持代理的连接方式\"\"\"\n",
    "    print 'Downloading:', url\n",
    "    headers = {'User-agent': 'Mozilla/5.0'}\n",
    "    request = urllib2.Request(url, headers=headers)\n",
    "    opener = urllib2.build_opener()\n",
    "    if proxy:\n",
    "        proxy_params = {urlparse.urlparse(url).scheme: proxy}\n",
    "        opener.add_handler(urllib2.ProxyHandler(proxy_params))\n",
    "    try:\n",
    "        html = opener.open(request).read()\n",
    "    except urllib2.URLError as e:\n",
    "        print 'Download error:', e.reason\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # 进行重试连接\n",
    "                html = download5(url, user_agent, proxy, num_retries-1)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实施："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print download('http://example.webscraping.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 各种爬虫的坑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 字符集编码问题（不要随意encode, decode；尽量统一字符集编码；了解web页面，本地，文件等编码格式）\n",
    "- HTML/XML不规范（必要时候还是使用正则表达）\n",
    "- 网页跳转（重定向，利用Selenium监听，找到实际数据存在页面）\n",
    "- Cookie/认证会话维护（直接Cookie，模拟登陆）\n",
    "- 代理维护（代理有效性测试，定期更新）\n",
    "- 超时问题\n",
    "- 内存优化\n",
    "- 异常维护（代码持续运行，爬虫性能，健壮性要求）\n",
    "- 代码框架的可扩展性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 爬虫攻防小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "阻挡方式：\n",
    "- 客户端请求的数据\n",
    "- 客户端请求的方式\n",
    "- 服务器端的数据组织和加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "相应策略：\n",
    "- 在headers中添加合适的数据进行欺骗\n",
    "- 使用代理服务\n",
    "- 模拟登陆，模拟登出\n",
    "- 控制爬取时间（robots.txt）\n",
    "- 使用Selenium+PhantomJS类似的库或者工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "反爬的手段：\n",
    "\n",
    "- 封禁\n",
    "- 投毒（地理位置）\n",
    "- 投毒（商家信息）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
